{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01785,
     "end_time": "2020-08-13T19:58:33.152368",
     "exception": false,
     "start_time": "2020-08-13T19:58:33.134518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kidney Disease Prediction - Problem statement 12 - Group 186\n",
    "\n",
    "Group No\tName\tStudent Email id\t% Contribution \\\n",
    "186\tSivarajan N\t2021FC04989@wilp.bits-pilani.ac.in\tEqual (100%) \\\n",
    "186\tSindhu C\t2021FC04993@wilp.bits-pilani.ac.in \tEqual (100%) \\\n",
    "186\tManibalan S\t2021fc04442@wilp.bits-pilani.ac.in\tNone (0%)\n",
    "\n",
    "The purpose of this notebook is to get you started to solve this problem.\n",
    "\n",
    "The main requirements are listed below which follows a standard Data Science Project:\n",
    "* Presteps\n",
    "1. Download Dataset from Google Drive - https://drive.google.com/file/d/1NykVFA1f5oGXZ5JlrBGXPBJrnfRncREh/view?usp=sharing\n",
    "2. Import the required libraries\n",
    "\n",
    "* I - Data Visualization & Exploration\n",
    "\t1. Print 2 rows for sanity check to identify all the features present in the dataset and if the target matches with them. \n",
    "\t2. Comment on class imbalance with appropriate visualization method. \n",
    "\t3. Provide appropriate visualizations to get an insight about the dataset. \n",
    "\t4. Do the correlational analysis on the dataset. Provide a visualization for the same. Justify the answer by answering this - Will this correlational analysis have effect on feature selection that we will perform in the next step? \n",
    "\n",
    "* II - Data Preprocessing, Feature Engineering & Cleaning\n",
    "\t1. Do the appropriate pre-processing of the data like identifying NULL or Missing Values if any, handling of outliers if present in the dataset, skewed data etc. Mention the pre-processing steps performed in the markdown cell. \n",
    "\t2. Apply appropriate feature engineering techniques for them. Apply the feature transformation techniques like Standardization, Normalization, etc. Apply the appropriate transformations depending upon the structure and the complexity of the dataset. Provide proper justification.\n",
    "\n",
    "* III - Model Building\n",
    "\t1. Split the dataset into training and test sets. Justify the choice of split. Experiment with different split to get the final split. Justify the method chosen. \n",
    "\t2. Build Model Development using Logistic Regression with penalty= l1 and l2, C= [1,0.5,0.1,0.01,0.003] . Identify the best parameter and justify your answer.\n",
    "\n",
    "* IV - Validation, Performance Evaluation, Testing\n",
    "\t1. Do the prediction for the test data and display the results for the inference. Calculate all the evaluation metrics and choose best for the model chosen. \n",
    "\t2. Comment on under fitting/overfitting/just right model. Justify the chosen model\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presteps\n",
    "    - Data is downloaded and saved in the same folder as this python notebook.\n",
    "    - Let's start by importing common data science packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:33.194168Z",
     "iopub.status.busy": "2020-08-13T19:58:33.193384Z",
     "iopub.status.idle": "2020-08-13T19:58:34.245924Z",
     "shell.execute_reply": "2020-08-13T19:58:34.246512Z"
    },
    "papermill": {
     "duration": 1.075531,
     "end_time": "2020-08-13T19:58:34.246755",
     "exception": false,
     "start_time": "2020-08-13T19:58:33.171224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # data visualization advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Data Visualization & Exploration\n",
    "\t1. Lets Print the first 2 rows for sanity check\n",
    "\t2. Comment on class imbalance with appropriate visualization method. \n",
    "\t3. Provide appropriate visualizations to get an insight about the dataset. \n",
    "\t4. Do the correlational analysis on the dataset. Provide a visualization for the same. Justify the answer by answering this - Will this correlational analysis have effect on feature selection that we will perform in the next step? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014696,
     "end_time": "2020-08-13T19:58:34.276970",
     "exception": false,
     "start_time": "2020-08-13T19:58:34.262274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:34.317535Z",
     "iopub.status.busy": "2020-08-13T19:58:34.316686Z",
     "iopub.status.idle": "2020-08-13T19:58:36.122740Z",
     "shell.execute_reply": "2020-08-13T19:58:36.121010Z"
    },
    "papermill": {
     "duration": 1.830985,
     "end_time": "2020-08-13T19:58:36.122993",
     "exception": false,
     "start_time": "2020-08-13T19:58:34.292008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset = pd.read_csv('kidney_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.166304Z",
     "iopub.status.busy": "2020-08-13T19:58:36.165501Z",
     "iopub.status.idle": "2020-08-13T19:58:36.206576Z",
     "shell.execute_reply": "2020-08-13T19:58:36.205770Z"
    },
    "papermill": {
     "duration": 0.067319,
     "end_time": "2020-08-13T19:58:36.206722",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.139403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp    sg   al   su  rbc      pc         pcc          ba  ...  \\\n",
       "0   0  48.0  80.0  1.02  1.0  0.0  NaN  normal  notpresent  notpresent  ...   \n",
       "1   1   7.0  50.0  1.02  4.0  0.0  NaN  normal  notpresent  notpresent  ...   \n",
       "\n",
       "   pcv    wc   rc  htn   dm  cad appet  pe ane classification  \n",
       "0   44  7800  5.2  yes  yes   no  good  no  no            ckd  \n",
       "1   38  6000  NaN   no   no   no  good  no  no            ckd  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 26 columns including id and classification is present in the data rows.\n",
    "- We are able to identify that all the features are present in the dataset and the target matches with them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016082,
     "end_time": "2020-08-13T19:58:36.469052",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.452970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. How many features are there? What are their datatypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.508408Z",
     "iopub.status.busy": "2020-08-13T19:58:36.507538Z",
     "iopub.status.idle": "2020-08-13T19:58:36.513412Z",
     "shell.execute_reply": "2020-08-13T19:58:36.512808Z"
    },
    "papermill": {
     "duration": 0.02818,
     "end_time": "2020-08-13T19:58:36.513560",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.485380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016295,
     "end_time": "2020-08-13T19:58:36.546533",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.530238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 25 features and one id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.590867Z",
     "iopub.status.busy": "2020-08-13T19:58:36.589934Z",
     "iopub.status.idle": "2020-08-13T19:58:36.594427Z",
     "shell.execute_reply": "2020-08-13T19:58:36.595159Z"
    },
    "papermill": {
     "duration": 0.032215,
     "end_time": "2020-08-13T19:58:36.595344",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.563129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     14\n",
       "float64    11\n",
       "int64       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.646654Z",
     "iopub.status.busy": "2020-08-13T19:58:36.645709Z",
     "iopub.status.idle": "2020-08-13T19:58:36.651438Z",
     "shell.execute_reply": "2020-08-13T19:58:36.650663Z"
    },
    "papermill": {
     "duration": 0.039373,
     "end_time": "2020-08-13T19:58:36.651586",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.612213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id\n",
       "0   0\n",
       "1   1\n",
       "2   2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.select_dtypes('int64').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.699025Z",
     "iopub.status.busy": "2020-08-13T19:58:36.698097Z",
     "iopub.status.idle": "2020-08-13T19:58:36.703553Z",
     "shell.execute_reply": "2020-08-13T19:58:36.702864Z"
    },
    "papermill": {
     "duration": 0.034997,
     "end_time": "2020-08-13T19:58:36.703694",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.668697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rbc      pc         pcc          ba pcv    wc   rc  htn   dm cad appet  \\\n",
       "0     NaN  normal  notpresent  notpresent  44  7800  5.2  yes  yes  no  good   \n",
       "1     NaN  normal  notpresent  notpresent  38  6000  NaN   no   no  no  good   \n",
       "2  normal  normal  notpresent  notpresent  31  7500  NaN   no  yes  no  poor   \n",
       "\n",
       "   pe  ane classification  \n",
       "0  no   no            ckd  \n",
       "1  no   no            ckd  \n",
       "2  no  yes            ckd  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.select_dtypes('object').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01699,
     "end_time": "2020-08-13T19:58:36.738213",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.721223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So there are 561 floats, 2 integers and 1 object. \\\n",
    "Of which the 2 integers (Id and Subject) aren't relevant for predictions. \\\n",
    "The 1 object is the Activity (target) that is to be predicted. \\\n",
    "Remaining all 561 features are real values from sensor data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016811,
     "end_time": "2020-08-13T19:58:36.772269",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.755458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Summarize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.813324Z",
     "iopub.status.busy": "2020-08-13T19:58:36.812226Z",
     "iopub.status.idle": "2020-08-13T19:58:36.816297Z",
     "shell.execute_reply": "2020-08-13T19:58:36.815590Z"
    },
    "papermill": {
     "duration": 0.026928,
     "end_time": "2020-08-13T19:58:36.816460",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.789532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017183,
     "end_time": "2020-08-13T19:58:36.851394",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.834211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Looking at the names of the features, it seems that these are medical data from India over 2-month period. \\\n",
    "The features starting with small 't' are time-domain features.\\\n",
    "The features starting with small 'f' are frequency-domain features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.892765Z",
     "iopub.status.busy": "2020-08-13T19:58:36.891770Z",
     "iopub.status.idle": "2020-08-13T19:58:36.895289Z",
     "shell.execute_reply": "2020-08-13T19:58:36.894599Z"
    },
    "papermill": {
     "duration": 0.026544,
     "end_time": "2020-08-13T19:58:36.895438",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.868894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = df_dataset.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:36.954901Z",
     "iopub.status.busy": "2020-08-13T19:58:36.954123Z",
     "iopub.status.idle": "2020-08-13T19:58:36.958037Z",
     "shell.execute_reply": "2020-08-13T19:58:36.957080Z"
    },
    "papermill": {
     "duration": 0.044968,
     "end_time": "2020-08-13T19:58:36.958191",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.913223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 26 is out of bounds for axis 0 with size 26",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13108/1419862714.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m563\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m't'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtime_feats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtime_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 26 is out of bounds for axis 0 with size 26"
     ]
    }
   ],
   "source": [
    "time_feats = []\n",
    "time_func = set()\n",
    "freq_feats = []\n",
    "freq_func = set()\n",
    "other_feats = []\n",
    "\n",
    "n_time = 0\n",
    "n_freq = 0\n",
    "n_other = 0\n",
    "\n",
    "regex_func = re.compile('-([a-z]+)')\n",
    "regex_axis = re.compile('-([A-Z])')\n",
    "\n",
    "for i in range(563):\n",
    "    if np.char.startswith(columns[i],'t'):\n",
    "        time_feats.append(columns[i])\n",
    "        time_func.add(regex_func.findall(columns[i])[0])\n",
    "        n_time += 1\n",
    "    elif np.char.startswith(columns[i],'f'):\n",
    "        freq_feats.append(columns[i])\n",
    "        freq_func.add(regex_func.findall(columns[i])[0])\n",
    "        n_freq += 1\n",
    "    else:\n",
    "        other_feats.append(columns[i])\n",
    "        n_other += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.001594Z",
     "iopub.status.busy": "2020-08-13T19:58:37.000150Z",
     "iopub.status.idle": "2020-08-13T19:58:37.005391Z",
     "shell.execute_reply": "2020-08-13T19:58:37.006157Z"
    },
    "papermill": {
     "duration": 0.03065,
     "end_time": "2020-08-13T19:58:37.006417",
     "exception": false,
     "start_time": "2020-08-13T19:58:36.975767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Time features:',sorted(time_func))\n",
    "print('Frequency features:',sorted(freq_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.050222Z",
     "iopub.status.busy": "2020-08-13T19:58:37.049320Z",
     "iopub.status.idle": "2020-08-13T19:58:37.054036Z",
     "shell.execute_reply": "2020-08-13T19:58:37.053030Z"
    },
    "papermill": {
     "duration": 0.028968,
     "end_time": "2020-08-13T19:58:37.054230",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.025262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Other features:',sorted(other_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.098246Z",
     "iopub.status.busy": "2020-08-13T19:58:37.097059Z",
     "iopub.status.idle": "2020-08-13T19:58:37.102743Z",
     "shell.execute_reply": "2020-08-13T19:58:37.101973Z"
    },
    "papermill": {
     "duration": 0.030026,
     "end_time": "2020-08-13T19:58:37.102911",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.072885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_time, n_freq, n_other, n_time + n_freq + n_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022375,
     "end_time": "2020-08-13T19:58:37.144020",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.121645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3. Is the target balanced? Let's check with appropriate visualization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.206243Z",
     "iopub.status.busy": "2020-08-13T19:58:37.205154Z",
     "iopub.status.idle": "2020-08-13T19:58:37.210830Z",
     "shell.execute_reply": "2020-08-13T19:58:37.209934Z"
    },
    "papermill": {
     "duration": 0.041708,
     "end_time": "2020-08-13T19:58:37.211025",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.169317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset['Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.267336Z",
     "iopub.status.busy": "2020-08-13T19:58:37.265767Z",
     "iopub.status.idle": "2020-08-13T19:58:37.480640Z",
     "shell.execute_reply": "2020-08-13T19:58:37.480045Z"
    },
    "papermill": {
     "duration": 0.244704,
     "end_time": "2020-08-13T19:58:37.480771",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.236067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart = sns.countplot(df_dataset['Activity'])\n",
    "t = chart.set_xticklabels(chart.get_xticklabels(),rotation=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017957,
     "end_time": "2020-08-13T19:58:37.517360",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.499403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Class Imbalance: \n",
    "    - Data Seems more or less balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018002,
     "end_time": "2020-08-13T19:58:37.553653",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.535651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4. Visualization for correlational analysis: \n",
    "- The simplest way to visualize correlation is to create a scatter plot of the two variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_dataset['Activity'],df_dataset['subject/Participant'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification:\n",
    "    - From the Scatter plot above, it is clearer that the data is more or less balanced. This correlational analysis above will not have an effect on the feature selection in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Data Preprocessing, Feature Engineering & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018002,
     "end_time": "2020-08-13T19:58:37.553653",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.535651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Data Preprocessing steps - null check, missing value check, handling outliers, checking skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values, so there are no standard missing values that pandas can detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting outliers using the Z-scores and Boxplot methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "def detect_outliers_zscore(data):\n",
    "    thres = 3\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    # print(mean, std)\n",
    "    for i in data:\n",
    "        z_score = (i-mean)/std\n",
    "        if (np.abs(z_score) > thres):\n",
    "            outliers.append(i)\n",
    "    return outliers# Driver code\n",
    "data_outliers = detect_outliers_zscore(df_dataset['subject/Participant'])\n",
    "print(\"Outliers from Z-scores method: \", data_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_dataset['subject/Participant'], vert=False)\n",
    "plt.title(\"Detecting outliers using Boxplot\")\n",
    "plt.xlabel('subject/Participant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no outliers in this dataset for 'subject/Participant' data.\n",
    "\n",
    "The following Data Pre-processing steps were done for this exercise:\n",
    " - identifying NULL or Missing Values if any\n",
    " - handling of outliers if present in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018002,
     "end_time": "2020-08-13T19:58:37.553653",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.535651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Feature Engineering - Which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.601035Z",
     "iopub.status.busy": "2020-08-13T19:58:37.600258Z",
     "iopub.status.idle": "2020-08-13T19:58:37.603854Z",
     "shell.execute_reply": "2020-08-13T19:58:37.603186Z"
    },
    "papermill": {
     "duration": 0.031991,
     "end_time": "2020-08-13T19:58:37.603995",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.572004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "act_map = {'STANDING':0, 'SITTING':1, 'LAYING':2, 'WALKING':3, 'WALKING_DOWNSTAIRS':4, 'WALKING_UPSTAIRS':5}\n",
    "df_dataset['activity_code'] = df_dataset['Activity'].map(act_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.705123Z",
     "iopub.status.busy": "2020-08-13T19:58:37.704051Z",
     "iopub.status.idle": "2020-08-13T19:58:37.709230Z",
     "shell.execute_reply": "2020-08-13T19:58:37.708480Z"
    },
    "papermill": {
     "duration": 0.03278,
     "end_time": "2020-08-13T19:58:37.709360",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.676580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset['activity_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:37.764054Z",
     "iopub.status.busy": "2020-08-13T19:58:37.755495Z",
     "iopub.status.idle": "2020-08-13T19:58:41.241707Z",
     "shell.execute_reply": "2020-08-13T19:58:41.242302Z"
    },
    "papermill": {
     "duration": 3.513978,
     "end_time": "2020-08-13T19:58:41.242470",
     "exception": false,
     "start_time": "2020-08-13T19:58:37.728492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,15))\n",
    "sns.heatmap(df_dataset[time_feats+['activity_code']].corr(), \n",
    "            cmap=sns.diverging_palette(240, 10, n=25), \n",
    "            cbar=True,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:41.296952Z",
     "iopub.status.busy": "2020-08-13T19:58:41.295767Z",
     "iopub.status.idle": "2020-08-13T19:58:45.520229Z",
     "shell.execute_reply": "2020-08-13T19:58:45.520822Z"
    },
    "papermill": {
     "duration": 4.256068,
     "end_time": "2020-08-13T19:58:45.520993",
     "exception": false,
     "start_time": "2020-08-13T19:58:41.264925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15,15))\n",
    "sns.heatmap(df_dataset[freq_feats+['activity_code']].corr(), \n",
    "            cmap=sns.diverging_palette(240, 10, n=25), \n",
    "            cbar=True,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025772,
     "end_time": "2020-08-13T19:58:45.573245",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.547473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# III - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025772,
     "end_time": "2020-08-13T19:58:45.573245",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.547473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Split the dataset into training and test sets:\n",
    "    - Justify the choice of split. Experiment with different split to get the final split. Justify the method chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:45.632953Z",
     "iopub.status.busy": "2020-08-13T19:58:45.632066Z",
     "iopub.status.idle": "2020-08-13T19:58:45.736522Z",
     "shell.execute_reply": "2020-08-13T19:58:45.735775Z"
    },
    "papermill": {
     "duration": 0.13723,
     "end_time": "2020-08-13T19:58:45.736659",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.599429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.079377,
     "end_time": "2020-08-13T19:58:45.842686",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.763309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's come up with a quick base model before further exploring the data. \\\n",
    "Firstly, let's remove subject, Activity from the data.\n",
    "And then split the data to train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:45.920541Z",
     "iopub.status.busy": "2020-08-13T19:58:45.919450Z",
     "iopub.status.idle": "2020-08-13T19:58:45.923726Z",
     "shell.execute_reply": "2020-08-13T19:58:45.923007Z"
    },
    "papermill": {
     "duration": 0.054797,
     "end_time": "2020-08-13T19:58:45.923881",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.869084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset.drop(columns=['subject/Participant','Activity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:45.986165Z",
     "iopub.status.busy": "2020-08-13T19:58:45.985025Z",
     "iopub.status.idle": "2020-08-13T19:58:45.989046Z",
     "shell.execute_reply": "2020-08-13T19:58:45.988319Z"
    },
    "papermill": {
     "duration": 0.038345,
     "end_time": "2020-08-13T19:58:45.989188",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.950843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_dataset.pop('activity_code')\n",
    "X = df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.053894Z",
     "iopub.status.busy": "2020-08-13T19:58:46.053047Z",
     "iopub.status.idle": "2020-08-13T19:58:46.057384Z",
     "shell.execute_reply": "2020-08-13T19:58:46.056777Z"
    },
    "papermill": {
     "duration": 0.039372,
     "end_time": "2020-08-13T19:58:46.057564",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.018192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification  - Lets' use 80:20 split\n",
    "- Since the number of values is 10299, 80:20 is better than 70:30. \n",
    "- With datasets containing considerably high observations like ours (> 10,000), 80:20 is a good starting point. Overall, we need to make sure that the test set represents most of the variance in the dataset. We can ensure this by trying different amounts of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.122098Z",
     "iopub.status.busy": "2020-08-13T19:58:46.121323Z",
     "iopub.status.idle": "2020-08-13T19:58:46.181417Z",
     "shell.execute_reply": "2020-08-13T19:58:46.180589Z"
    },
    "papermill": {
     "duration": 0.094948,
     "end_time": "2020-08-13T19:58:46.181570",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.086622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.244261Z",
     "iopub.status.busy": "2020-08-13T19:58:46.243193Z",
     "iopub.status.idle": "2020-08-13T19:58:46.247522Z",
     "shell.execute_reply": "2020-08-13T19:58:46.246748Z"
    },
    "papermill": {
     "duration": 0.037618,
     "end_time": "2020-08-13T19:58:46.247650",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.210032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.328781Z",
     "iopub.status.busy": "2020-08-13T19:58:46.327833Z",
     "iopub.status.idle": "2020-08-13T19:58:46.332018Z",
     "shell.execute_reply": "2020-08-13T19:58:46.332565Z"
    },
    "papermill": {
     "duration": 0.056229,
     "end_time": "2020-08-13T19:58:46.332738",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.276509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025772,
     "end_time": "2020-08-13T19:58:45.573245",
     "exception": false,
     "start_time": "2020-08-13T19:58:45.547473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression - Identify the best parameter: \n",
    "    - Build Model Development using Logistic Regression with penalty= l1 and l2, C= [1,0.5,0.1,0.01,0.003] . Identify the best parameter and justify your answer.\n",
    "    \n",
    "    - Penalized logistic regression imposes a penalty to the logistic model for having too many variables. This results in shrinking the coefficients of the less contributive variables toward zero. This is also known as regularization.\n",
    "    \n",
    "    - In Machine Learning, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features. For our case, we use L1 since we need drop variabls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.393407Z",
     "iopub.status.busy": "2020-08-13T19:58:46.392643Z",
     "iopub.status.idle": "2020-08-13T19:58:46.479707Z",
     "shell.execute_reply": "2020-08-13T19:58:46.479071Z"
    },
    "papermill": {
     "duration": 0.119958,
     "end_time": "2020-08-13T19:58:46.479860",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.359902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026929,
     "end_time": "2020-08-13T19:58:46.534340",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.507411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's do feature standardization before training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.603894Z",
     "iopub.status.busy": "2020-08-13T19:58:46.603133Z",
     "iopub.status.idle": "2020-08-13T19:58:46.732022Z",
     "shell.execute_reply": "2020-08-13T19:58:46.731354Z"
    },
    "papermill": {
     "duration": 0.170449,
     "end_time": "2020-08-13T19:58:46.732166",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.561717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "le = preprocessing.LabelEncoder()\n",
    "X_train = X_train.apply(le.fit_transform) # this is needed to avoid string transformation\n",
    "X_test = X_test.apply(le.fit_transform) # this is needed to avoid string transformation\n",
    "\n",
    "X_prep_train = std_scaler.fit_transform(X_train)\n",
    "X_prep_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification - Feature transformation techniques using Standardization\n",
    "    - Standardization is a scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.\n",
    "    - Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1.\n",
    "    - The appropriate transformation depending upon the structure and the complexity of our dataset is Standardization. Unlike normalization, standardization does not have a bounding range.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027151,
     "end_time": "2020-08-13T19:58:46.786873",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.759722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:46.848643Z",
     "iopub.status.busy": "2020-08-13T19:58:46.847872Z",
     "iopub.status.idle": "2020-08-13T19:58:47.993313Z",
     "shell.execute_reply": "2020-08-13T19:58:47.992120Z"
    },
    "papermill": {
     "duration": 1.179101,
     "end_time": "2020-08-13T19:58:47.993454",
     "exception": false,
     "start_time": "2020-08-13T19:58:46.814353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform GridSearchCV to tune best-fit LR model\n",
    "param = {'C': [1,0.5,0.1,0.01,0.003]}\n",
    "\n",
    "LR_clf = LogisticRegression(penalty='l1', solver='liblinear') # liblinear supports logistic regression (LR) L1-regularized classifiers \n",
    "gs_model = GridSearchCV(estimator=LR_clf, param_grid=param)\n",
    "gs_model.fit(X_prep_train, y_train)\n",
    "\n",
    "y_pred = gs_model.predict(X_prep_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-08-13T19:58:48.051249",
     "exception": false,
     "start_time": "2020-08-13T19:58:48.023736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**WOW** - that was a good Classification.\n",
    "### Justification:\n",
    "- Precision:- Accuracy of positive predictions, is perfect 1.00\n",
    "- Recall:- Fraction of positives that were correctly identified. - is also 1.00\n",
    "- F1 score — percent of positive predictions were correct - is perfect 1.00\n",
    "- Support - is the number of actual occurrences of the class in the specified dataset. \n",
    "\n",
    "Model accuracy is 1.00 the highest we’ve seen of each respective metric from all models so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027486,
     "end_time": "2020-08-13T19:58:48.106612",
     "exception": false,
     "start_time": "2020-08-13T19:58:48.079126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:48.183809Z",
     "iopub.status.busy": "2020-08-13T19:58:48.182690Z",
     "iopub.status.idle": "2020-08-13T19:58:48.186610Z",
     "shell.execute_reply": "2020-08-13T19:58:48.187602Z"
    },
    "papermill": {
     "duration": 0.052077,
     "end_time": "2020-08-13T19:58:48.187858",
     "exception": false,
     "start_time": "2020-08-13T19:58:48.135781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:48.272184Z",
     "iopub.status.busy": "2020-08-13T19:58:48.271140Z",
     "iopub.status.idle": "2020-08-13T19:58:48.275537Z",
     "shell.execute_reply": "2020-08-13T19:58:48.274527Z"
    },
    "papermill": {
     "duration": 0.04615,
     "end_time": "2020-08-13T19:58:48.275717",
     "exception": false,
     "start_time": "2020-08-13T19:58:48.229567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:48.352630Z",
     "iopub.status.busy": "2020-08-13T19:58:48.349447Z",
     "iopub.status.idle": "2020-08-13T19:58:52.811504Z",
     "shell.execute_reply": "2020-08-13T19:58:52.810742Z"
    },
    "papermill": {
     "duration": 4.500243,
     "end_time": "2020-08-13T19:58:52.811661",
     "exception": false,
     "start_time": "2020-08-13T19:58:48.311418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(LR_clf, X_prep_train, y_train, scoring='accuracy', cv=kfold)\n",
    "print('Scores:',scores)\n",
    "print('Mean:',np.mean(scores))\n",
    "print('Std:',np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02796,
     "end_time": "2020-08-13T19:58:52.875551",
     "exception": false,
     "start_time": "2020-08-13T19:58:52.847591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Amazing** \\\n",
    "How about on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:52.939526Z",
     "iopub.status.busy": "2020-08-13T19:58:52.938746Z",
     "iopub.status.idle": "2020-08-13T19:58:52.957428Z",
     "shell.execute_reply": "2020-08-13T19:58:52.956447Z"
    },
    "papermill": {
     "duration": 0.053738,
     "end_time": "2020-08-13T19:58:52.957628",
     "exception": false,
     "start_time": "2020-08-13T19:58:52.903890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_model.fit(X_prep_test, y_test)\n",
    "y_pred = gs_model.predict(X_prep_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02843,
     "end_time": "2020-08-13T19:58:53.014908",
     "exception": false,
     "start_time": "2020-08-13T19:58:52.986478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Superb**, results on test data are consistent with train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0279,
     "end_time": "2020-08-13T19:58:53.072059",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.044159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029511,
     "end_time": "2020-08-13T19:58:53.130126",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.100615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Given the excellent results here, let's try to submit a solution and see what score we get on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.265725Z",
     "iopub.status.busy": "2020-08-13T19:58:53.264642Z",
     "iopub.status.idle": "2020-08-13T19:58:53.268202Z",
     "shell.execute_reply": "2020-08-13T19:58:53.267533Z"
    },
    "papermill": {
     "duration": 0.036878,
     "end_time": "2020-08-13T19:58:53.268333",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.231455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dataset = df_dataset.reindex(labels=df_dataset.columns,axis=1)\n",
    "X_final_test = df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.341810Z",
     "iopub.status.busy": "2020-08-13T19:58:53.341052Z",
     "iopub.status.idle": "2020-08-13T19:58:53.357393Z",
     "shell.execute_reply": "2020-08-13T19:58:53.356624Z"
    },
    "papermill": {
     "duration": 0.060646,
     "end_time": "2020-08-13T19:58:53.357532",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.296886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_final_prep_test = std_scaler.transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.420483Z",
     "iopub.status.busy": "2020-08-13T19:58:53.419651Z",
     "iopub.status.idle": "2020-08-13T19:58:53.428659Z",
     "shell.execute_reply": "2020-08-13T19:58:53.427892Z"
    },
    "papermill": {
     "duration": 0.04247,
     "end_time": "2020-08-13T19:58:53.428818",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.386348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_final_pred = gs_model.predict(X_final_prep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.493307Z",
     "iopub.status.busy": "2020-08-13T19:58:53.492200Z",
     "iopub.status.idle": "2020-08-13T19:58:53.497554Z",
     "shell.execute_reply": "2020-08-13T19:58:53.496843Z"
    },
    "papermill": {
     "duration": 0.040067,
     "end_time": "2020-08-13T19:58:53.497679",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.457612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.565320Z",
     "iopub.status.busy": "2020-08-13T19:58:53.564404Z",
     "iopub.status.idle": "2020-08-13T19:58:53.568666Z",
     "shell.execute_reply": "2020-08-13T19:58:53.567939Z"
    },
    "papermill": {
     "duration": 0.042239,
     "end_time": "2020-08-13T19:58:53.568811",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.526572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rev_act_map = {0:'STANDING', 1:'SITTING', 2:'LAYING', 3:'WALKING', 4:'WALKING_DOWNSTAIRS', 5:'WALKING_UPSTAIRS'}\n",
    "y_final = [rev_act_map[code] for code in y_final_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.634450Z",
     "iopub.status.busy": "2020-08-13T19:58:53.633561Z",
     "iopub.status.idle": "2020-08-13T19:58:53.742502Z",
     "shell.execute_reply": "2020-08-13T19:58:53.743104Z"
    },
    "papermill": {
     "duration": 0.145761,
     "end_time": "2020-08-13T19:58:53.743300",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.597539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": range(1,len(y_final)+1),\n",
    "        \"Activity\": y_final\n",
    "    })\n",
    "\n",
    "submission.to_csv('lr_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T19:58:53.812719Z",
     "iopub.status.busy": "2020-08-13T19:58:53.811898Z",
     "iopub.status.idle": "2020-08-13T19:58:53.817087Z",
     "shell.execute_reply": "2020-08-13T19:58:53.816483Z"
    },
    "papermill": {
     "duration": 0.044968,
     "end_time": "2020-08-13T19:58:53.817220",
     "exception": false,
     "start_time": "2020-08-13T19:58:53.772252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justifcation - under fitting/overfitting/just right model\n",
    "Ideally, you want to select a model at the sweet spot between underfitting and overfitting.\n",
    "\n",
    "There are three main methods to avoid overfitting: \\\n",
    "1- Keep the model simpler: reduce variance by taking into account fewer variables and parameters, thereby removing some of the noise in the training data. \\\n",
    "2- Use cross-validation techniques such as k-folds cross-validation. \\\n",
    "3- Use regularization techniques such as Linear Regression that penalize certain model parameters if they’re likely to cause overfitting.\n",
    "\n",
    "In our case, we have followed all the three methods above by using fewer variables, validating using k-folds and regularization of parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "duration": 25.912771,
   "end_time": "2020-08-13T19:58:54.012281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-13T19:58:28.099510",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
